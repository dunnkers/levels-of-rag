{
    "guid": {
        "17": "a2eb19a3-1642-5781-bb82-45b681556560",
        "64": "360bdd08-ebe7-5569-9654-59b2c15e9505",
        "25": "03ccd5af-7a72-58de-acbf-200dc5891883",
        "57": "795350ad-6bec-5f36-b011-fb242a977bef",
        "54": "2c108787-14a0-5b3b-91df-80d011479465",
        "31": "aa661e50-ef5d-5d3a-8b84-2d798207eca0",
        "40": "b2343a84-726c-599a-8ef4-c1d3992a6ded",
        "22": "554060c9-cd90-52de-8c63-a534ef68168b",
        "69": "cdc3ef0a-718c-5330-b7cf-a8bf3db2a3f6",
        "9": "ab2ef9d4-8af9-54d7-a3fe-272999159d7b",
        "32": "b883c44e-ef8a-5f2f-9fd8-2cb8e958d4a7",
        "21": "44976e6d-e92c-5a5f-94cd-e32b6c798e5e",
        "55": "82194198-ad3c-5909-b0f5-5ad591a2b815",
        "59": "bf13b897-74b8-5593-88c5-f547b655b25b",
        "71": "654f9047-1ee1-57d0-95f7-220b16370422",
        "70": "4b443472-06fa-57a1-9682-a12461da68bf"
    },
    "logo": {
        "17": "",
        "64": "",
        "25": "",
        "57": "",
        "54": "",
        "31": "",
        "40": "",
        "22": "",
        "69": "\/media\/cfp\/submissions\/G8VWGY\/Screenshot_2024-06-29_at_17.07.32_W5To5r0.png",
        "9": "",
        "32": "",
        "21": "",
        "55": "\/media\/cfp\/submissions\/8QNFLU\/AC_Profile_picture_-_Marc_1_da8pCEz.jpg",
        "59": "",
        "71": "",
        "70": ""
    },
    "date": {
        "17": "2024-07-11T10:00:00+02:00",
        "64": "2024-07-11T11:15:00+02:00",
        "25": "2024-07-11T12:00:00+02:00",
        "57": "2024-07-11T14:00:00+02:00",
        "54": "2024-07-11T14:45:00+02:00",
        "31": "2024-07-11T16:05:00+02:00",
        "40": "2024-07-11T16:50:00+02:00",
        "22": "2024-07-11T10:00:00+02:00",
        "69": "2024-07-11T11:15:00+02:00",
        "9": "2024-07-11T12:00:00+02:00",
        "32": "2024-07-11T14:00:00+02:00",
        "21": "2024-07-11T14:45:00+02:00",
        "55": "2024-07-11T16:05:00+02:00",
        "59": "2024-07-11T16:50:00+02:00",
        "71": "2024-07-11T09:00:00+02:00",
        "70": "2024-07-11T17:30:00+02:00"
    },
    "start": {
        "17": "10:00",
        "64": "11:15",
        "25": "12:00",
        "57": "14:00",
        "54": "14:45",
        "31": "16:05",
        "40": "16:50",
        "22": "10:00",
        "69": "11:15",
        "9": "12:00",
        "32": "14:00",
        "21": "14:45",
        "55": "16:05",
        "59": "16:50",
        "71": "09:00",
        "70": "17:30"
    },
    "duration": {
        "17": "00:30",
        "64": "00:30",
        "25": "00:30",
        "57": "00:30",
        "54": "00:30",
        "31": "00:30",
        "40": "00:30",
        "22": "00:30",
        "69": "00:30",
        "9": "00:30",
        "32": "00:30",
        "21": "00:30",
        "55": "00:30",
        "59": "00:30",
        "71": "00:50",
        "70": "01:00"
    },
    "room": {
        "17": "If (1.1)",
        "64": "If (1.1)",
        "25": "If (1.1)",
        "57": "If (1.1)",
        "54": "If (1.1)",
        "31": "If (1.1)",
        "40": "If (1.1)",
        "22": "Else (1.3)",
        "69": "Else (1.3)",
        "9": "Else (1.3)",
        "32": "Else (1.3)",
        "21": "Else (1.3)",
        "55": "Else (1.3)",
        "59": "Else (1.3)",
        "71": "REPL (2, mainstage)",
        "70": "REPL (2, mainstage)"
    },
    "slug": {
        "17": "cfp-17-explainable-ai-in-the-lime-light",
        "64": "cfp-64-risks-and-mitigations-for-a-safe-and-responsible-ai",
        "25": "cfp-25-predicting-the-spring-classics-of-cycling-with-my-first-neural-network",
        "57": "cfp-57-computer-vision-at-the-dutch-tennis-federation-utilizing-yolo-to-create-insights-for-coaches",
        "54": "cfp-54-enhancing-event-analysis-at-scale-leveraging-tracking-data-in-sports-",
        "31": "cfp-31-how-i-lost-1000-betting-on-cs-go-with-machine-learning-and-python",
        "40": "cfp-40--the-taller-the-tree-the-harder-the-fall-determining-tree-height-from-space-using-deep-learning-and-very-high-resolution-satellite-imagery-",
        "22": "cfp-22-bertopic-to-accelerate-ukrainian-aid-by-the-red-cross",
        "69": "cfp-69-the-levels-of-rag-",
        "9": "cfp-9-scikit-learn-can-do-that-",
        "32": "cfp-32-evaluating-llm-frameworks",
        "21": "cfp-21-maximizing-marketplace-experimentation-switchback-design-for-small-samples-and-subtle-effects",
        "55": "cfp-55-causal-forecasting-how-to-disentangle-causal-effects-while-controlling-for-unobserved-confounders-and-keeping-accuracy",
        "59": "cfp-59-cloud-no-thanks-i-m-gonna-run-genai-on-my-ai-pc",
        "71": "cfp-71-software-at-asml-the-force-behind-making-microchips",
        "70": "cfp-70-sonic-pi-live-coding-as-a-tool-for-next-gen-education-"
    },
    "url": {
        "17": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/QFW9XN\/",
        "64": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/ZWTNSH\/",
        "25": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/7A7YQC\/",
        "57": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/UGNXZY\/",
        "54": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/BWC9DD\/",
        "31": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/WP7S3A\/",
        "40": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/XXCFDM\/",
        "22": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/X7GXYH\/",
        "69": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/G8VWGY\/",
        "9": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/3BF9AT\/",
        "32": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/33M979\/",
        "21": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/KBYKXY\/",
        "55": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/8QNFLU\/",
        "59": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/SMX9CS\/",
        "71": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/LKGBYR\/",
        "70": "https:\/\/eindhoven2024.pydata.org\/cfp\/talk\/XYLXUP\/"
    },
    "title": {
        "17": "Explainable AI in the LIME-light",
        "64": "Risks and Mitigations for a Safe and Responsible AI",
        "25": "Predicting the Spring Classics of cycling with my first neural network",
        "57": "Computer vision at the Dutch Tennis Federation: Utilizing YOLO to create insights for coaches",
        "54": "Enhancing Event Analysis at Scale: Leveraging Tracking Data in Sports.",
        "31": "How I lost 1000\u20ac betting on CS:GO with machine learning and Python",
        "40": "\ud83c\udf33 The taller the tree, the harder the fall. Determining tree height from space using Deep Learning and very high resolution satellite imagery \ud83d\udef0\ufe0f",
        "22": "BERTopic to accelerate Ukrainian aid by the Red Cross",
        "69": "The Levels of RAG \ud83e\udd9c",
        "9": "Scikit-Learn can do THAT?!",
        "32": "Evaluating LLM Frameworks",
        "21": "Maximizing marketplace experimentation: switchback design for small samples and subtle effects",
        "55": "Causal Forecasting: How to disentangle causal effects, while controlling for unobserved confounders and keeping accuracy",
        "59": "Cloud? No Thanks! I\u2019m Gonna Run GenAI on My AI PC",
        "71": "Software at ASML: the Force behind making microchips",
        "70": "Sonic Pi - Live Coding as a tool for next-gen education."
    },
    "subtitle": {
        "17": "",
        "64": "",
        "25": "",
        "57": "",
        "54": "",
        "31": "",
        "40": "",
        "22": "",
        "69": "",
        "9": "",
        "32": "",
        "21": "",
        "55": "",
        "59": "",
        "71": "",
        "70": ""
    },
    "track": {
        "17": null,
        "64": null,
        "25": "PySport - Sports Analytics",
        "57": "PySport - Sports Analytics",
        "54": "PySport - Sports Analytics",
        "31": null,
        "40": null,
        "22": null,
        "69": null,
        "9": null,
        "32": null,
        "21": null,
        "55": null,
        "59": null,
        "71": null,
        "70": null
    },
    "type": {
        "17": "Talk",
        "64": "Talk",
        "25": "Talk",
        "57": "Talk",
        "54": "Talk",
        "31": "Talk",
        "40": "Talk",
        "22": "Talk",
        "69": "Talk",
        "9": "Talk",
        "32": "Talk",
        "21": "Talk",
        "55": "Talk",
        "59": "Talk",
        "71": "Talk",
        "70": "Talk"
    },
    "language": {
        "17": "en",
        "64": "en",
        "25": "en",
        "57": "en",
        "54": "en",
        "31": "en",
        "40": "en",
        "22": "en",
        "69": "en",
        "9": "en",
        "32": "en",
        "21": "en",
        "55": "en",
        "59": "en",
        "71": "en",
        "70": "en"
    },
    "abstract": {
        "17": "LIME, a model-agnostic AI framework, illuminates the path to local explainability, primarily for classification models. Delving into the theory underpinning LIME, we explore diverse use cases and its adaptability across various scenarios. Through practical examples, we showcase the breadth of applications for LIME. By the presentation's conclusion, you'll have gained insights into leveraging LIME to clarify individual prediction logic, leading to more accessible explanations.",
        "64": "This talk will explain the multifaceted risks associated with building custom AI solutions, both from Responsible AI and Safety perspectives, and explore ways to mitigate them, to ensure that as AI professionals we create non-harmful AI systems.",
        "25": "Last year I attended PyData Eindhoven for the first time. I got inspired and now I\u2019m back to present my first neural network, a network that was trained to predict the Spring Classics of cycling! With this neural network, I\u2019m attempting to beat my friends, and myself, in a well-known fantasy cycling game.",
        "57": "Through single-camera tennis match footage, via a YOLO-driven computer vision system, and culminating in actionable insights for strength and conditioning coaches, the Dutch Tennis Federation offers a pathway for creating tennis data and insights. In our presentation, we will delve into technical specifications and algorithms of our system, navigate through the challenges of working with tennis video footage, and elaborate on our approach to actively engage coaches in our co-creation approach. After the presentation, you will have a deeper understanding of the intricate workings behind implementing such system in a competitive tennis environment. All output of the project will be presented on Github.",
        "54": "Learn how to automate the generation of contextual metrics from tracking data to enrich event analysis, handling the influx of games arriving daily in an efficient way by scaling-out the entire architecture.",
        "31": "People have been using machine learning for sports betting for decades. Logistic regression applied to horse racing made someone a multi-millionaire in the 80s. While fun, betting is a losing proposition for most. The house always wins, right?\r\n\r\nWith a friend, I thought we could beat the house in e-sports by leveraging modern ML tools like LightGBM. E-sports betting is less sophisticated than football or horse racing i.e. the market is less efficient. There is a lot of online data and unknown teams. It was a space ripe for money-making, or so we thought.\r\n\r\nFirst, I will explain the theory behind e-sports betting with ML: what is an edge, financial decision-making, the expected value and decision rule for one bet, multiple bets with the Kelly criterion, probability calibration and the winner's curse.\r\n\r\nThen, I will explain how we built a web scraper to extract features, developed a probabilistic classifier using LightGBM, defined betting rules using the Kelly criterion, backtested it with a positive ROI, and then lost actual money, with many priceless lessons coming out of it.",
        "40": "A case study of how we use Deep Learning based photogrammetry to calculate the height of trees from very high resolution satellite imagery. We show the substantial improvement achieved by switching from classical photogrammetric techniques to a deep learning based model (implemented in PyTorch), and the challenges we had to overcome to make this solution work.",
        "22": "By means of Topic Modeling, discussed topics can be subtracted from a set of documents. BERTopic is a way of Topic Modeling that uses Large Language Models. A high-level overview of how BERTopic works will be presented, together with its evaluation and the application of it on a use case of the Netherlands Red Cross. In this use case, BERTopic supports in getting insights into the needs of Ukrainian refugees as expressed through social media.  This presentation will help in understanding BERTopic and might inspire for other valuable use cases within your own field.",
        "69": "LLM's can be supercharged using a technique called RAG, allowing us to overcome dealbreaker problems like hallucinations or no access to internal data. RAG is gaining more industry momentum and is becoming rapidly more mature both in the open-source world and at major Cloud vendors. But what can we expect from RAG? What is the current state of the tech in the industry? What use-cases work well and which are more challenging? Let's find out together!",
        "9": "Many of us know scikit-learn for it's ability to construct pipelines that can do .fit().predict(). It's an amazing feature for sure. But once you dive into the codebase ... you realise that there is just so much more. \r\n\r\nThis talk will be an attempt at demonstrating some extra features in scikit-learn, and it's ecosystem, that are less common but deserve to be in the spotlight. \r\n\r\nIn particular I hope to discuss these things that scikit-learn can do:\r\n\r\n- sparse datasets and models\r\n- larger than memory datasets\r\n- sample weight techniques\r\n- image classification via embeddings\r\n- tabular embeddings\/vectorisation \r\n- data deduplication\r\n- pipeline caching\r\n\r\nIf time allows I may also touch on extra topics.",
        "32": "Large Language Models are everywhere these days. But how can you objectively evaluate whether a model or a prompt is performing properly? Let's dive into the world of LLM evaluation frameworks!",
        "21": "Conventional A\/B testing often falls short in industries such as airlines, ride-sharing, and delivery services, where challenges like small samples and subtle effects complicate testing new features. Inspired by its significant impact in leading companies like Uber, Lyft, and Doordash, we introduce the switchback design as a practical alternative to conventional A\/B testing. By addressing small sample size limitations and the need to detect subtle effects quickly, this approach boosts statistical power while reducing variability and interference. We guide the audience through the challenges of marketplace experimentation and implementing this approach, period length optimization and switch frequency using a case study from the airline industry.",
        "55": "A lot of industry-available Machine Learning solutions for causal forecasting have a very particular blind spot: unobserved confounders. We will present an approach that allows you to combine state-of-the-art Machine Learning approaches with advanced Econometrics techniques to get the better of both worlds: accurate causal inference and good forecasting accuracy.",
        "59": "In this speech, we want to introduce an AI PC, a single machine that consists of a CPU, GPU, and NPU (Neural Processing Unit) and can run GenAI in seconds, not hours. Besides the hardware, we will also show the OpenVINO Toolkit, a software solution that helps squeeze as much as possible out of that PC. Join our talk and see for yourself the AI PC is good for both generative and conventional AI models. All presented demos are open source and available on our GitHub.",
        "71": "In a rapidly evolving landscape of semiconductor manufacturing, ASML\u2019s advanced lithography technologies are pivotal in driving Moore\u2019s Law forward. The focus of this talk is ASML\u2019s holistic approach to Software development and acceleration of Software delivery to customers. In addition, we discuss how ASML engages and cultivates Software talents. At the end of this presentation the attendees will have an understanding of ASML\u2019s software ecosystem and its critical role in advancing the future.",
        "70": "Sonic Pi is a free code-based music creation and performance tool that targets both education and professional musicians. It is possible for beginners to code fresh beats, driving bass lines and shimmering synth riffs. All this whilst teaching core computer science concepts such as sequencing, functions, variables, loops, data structures and algorithms.\r\n\r\nThis talk will briefly introduce Sonic Pi before taking a deep technical nose-dive into some of the interesting requirements of live coding."
    },
    "description": {
        "17": "Although AI toolkits have simplified model implementation, understanding and interpreting these models remain challenging. With regulatory frameworks like the EU AI Act emphasizing explainability, the need for tools like LIME is paramount.\r\n\r\nThis presentation will provide an in-depth overview of LIME (Local Interpretable Model-agnostic Explanations), highlighting its utility in facilitating model comprehension. No prior expertise is assumed. Beginning with an explanation of LIME's theory and its practical implementation in Python, we'll then delve into diverse classification scenarios to showcase LIME's effectiveness. Additionally, we'll explore how the original LIME framework has been extended to handle time series data.",
        "64": "The rapid advancement of AI technologies, especially in the LLM space, is opening countless opportunities across all industries to apply in their daily business. However, it also introduces significant risks that could impact their users and broader society, from ethical and safety perspectives.\r\n\r\nIn this talk we will delve into various aspects to consider when building custom AI solutions to ensure they are not harmful in any way. We'll explain the types of risks to assess from both Responsible AI and Safety perspectives, and what mitigations can be implemented to address them. We'll discuss broad aspects that apply to all AI systems, such as fairness and inclusiveness, as well as risks specific to Large Language Models, like prompt injection attacks and hallucinations.\r\n \r\nBy the end of this talk, participants will have a clear understanding of AI risks, and a practical framework for evaluating and implementing responsible AI practices when building AI-based applications.\r\n \r\nThe talk is designed for anyone involved in the design and development of AI systems, from AI developers and data scientists to project managers. No technical knowledge is required, but a prior understanding of the fundamentals of AI and LLMs is assumed.",
        "25": "Last year I attended PyData Eindhoven for the first time. I got inspired and now I\u2019m back to present my first neural network, a network that was trained to predict the Spring Classics of cycling! With this neural network, I\u2019m attempting to beat my friends, and myself, in a well-known fantasy cycling game.\r\n\r\nIn this talk, I will elaborate on the process of building a model from scratch. This will include data collection, model training and finetuning, and of course a discussion of the predicted results. The predictions will also be compared to an existing cycling prediction platform that I use as benchmark. Lastly, I\u2019ll try to provide some insights into the model using SHAP values.",
        "57": "Tennis is seen within the community more as a skill sport than a physical sport. In this way, tennis is an exception compared to other ball sports, in which there is a primary focus on physical data (e.g., distance covered or time in specific speed zones). The primary use of data by now is tactical analysis, scouting your opponent, and finding specific tendencies. Currently, this is done by manually annotating events in game videos for further analysis, which can take up to 5 hours per match. One of the bottlenecks of this process is finding the start of a rally; the effective playing time is actually just 20-30% on clay courts and 10-15% on fast courts. This means that a 5-hour match would have just 30 minutes of playing time that needs to be annotated. Hence, automatically finding the start point of a rally and cutting videos into shorter sequences would tremendously speed up the annotation process and would allow scouting of more players and matches. \r\n\r\nIn turn, we had two goals in the project. First, to create a solution to optimize the annotation process by providing videos when the ball is in play. The second goal was to provide tennis coaches and players with physical data and to stimulate the use of this type of data (user buy-in). For both of these goals, we faced specific challenges we needed to overcome. Event recognition has been achieved in other sports as well as in tennis using computer vision approaches, especially video tracking (trajectories and coordinates of the players). In tennis, the Hawk-Eye system is used in big tournaments to provide this information. By using 10 synchronized cameras, the system provides player and ball trajectories that enable event recognition and the extraction of physical variables. However, due to the costs of using this system and the complexity of installing it, using it in less prestigious tournaments or for training monitoring is not an option. To overcome this challenge, we created a one-camera computer vision system that allows for player tracking and simple event recognition. \r\n\r\nAs mentioned earlier, the second challenge of this project is the buy-in by coaches, athletes, and the medical team to physical parameters for athlete monitoring and training optimization. To overcome this problem, we opted for an educational and co-creation approach. This entails, in an initial step, a presentation on the usage of physical data in other sports and their benefits. In a second step, we performed semi-structured interviews with potential end-users (coaches, athletes, medical staff, and performance analysts). Based on these interactive interviews, important variables for the end-users were defined. In addition, potential forms of data presentation and visualizations were discussed in order to create a dashboard for the end-users. In doing so, we improved the understanding of the end-users as well as the commitment to the project. \r\n\r\nIn this talk, we will provide a summary of the general approach of the conducted interviews and how this resulted in an interactive dashboard for coaches, athletes, and analysts. In addition, we provide an overview of the pipeline of the computer vision approach. While using an \u201coff-the-shelf\u201d YOLO approach, several processing steps are necessary. This includes several technical challenges like player and court recognition as well as data filtering. We will also provide an example of how we enriched our pipeline with audio data to facilitate event recognition. All in all, we hope to provide an exemplary approach on how to conduct a data science project in a sports environment in which the conceptual barriers between product designer and end-user are often hard to overcome.",
        "54": "In the dynamic landscape of sports analytics, the integration of tracking data has opened new frontiers for in-depth event analysis. Yet, the use of this data remains a bottleneck, particularly when dealing with a large volume of games. Indeed, such computation is either too expensive or too long. The focus of the presentation will be on automating the generation of these contextual metrics at scale, and their usage by professionals and decision-makers.\r\nThe presentation will showcase an architecture and an automated pipeline designed to handle the influx of games. Leveraging Python and cloud computing services such as message queues, we efficiently manage incoming game data by scaling the infrastructure based on the workload, ensuring optimal performance during peak period while minimizing costs during quieter times. The presentation will strike a balance between technical depth and practical application. Attendees will gain insights into the architecture required to efficiently process hundreds of games weekly, while accommodating the thousands already present in the database. The advantage granted by this method will be quantified in terms of time and resources to inform data scientists and data engineers the efficiency they could reach.",
        "31": "This presentation goes in-depth on how to use ML for e-sports betting and the pitfalls one might fall in. More broadly, I try to connect ML with financial decision-making, which can be applied in other domains too (credit, fraud, marketing), targeting data scientists and ML practitioners who are interested in financial applications.\r\n\r\nFinancial decision-making is not just about being right (predictive modelling) but also about acting rightly (betting\/trading strategy). To act correctly, one must understand concepts such as an edge, expected value\/profits, probability calibration, winner's curse (selection bias), and so on. More importantly, any trading or betting strategy needs to be thoroughly validated with backtests and paper-trades and the risk and profitability quantified. My aim is to cover some of those important foundational topics, while providing pointers for further studies.\r\n\r\nThe presentation is divided into two parts: \r\n\r\n1. Foundations of ML applied to betting (15 min)\r\n   * What is your edge?\r\n   * Financial decision-making with ML\r\n   * One bet: Expected profits and decision rule\r\n   * Multiple bets: The Kelly criterion\r\n   * Probability calibration\r\n   * Winner\u2019s curse\r\n2. CS:GO betting (10 min)\r\n   * Data scraping\r\n   * Feature engineering\r\n   * TrueSkill (with a side note on inferential vs predictive models)\r\n   * Modelling\r\n   * Evaluation\r\n   * Backtesting\r\n   * Why I lost 1000 euros\r\n\r\nThat is, I will present both the theory and practice, using my own failure as an illustrative example for the lessons shown. The presentation will have two companion blog posts with reproducible Python code.\r\n\r\nThis presentation requires mid-level data science knowledge (e.g. how to train a gradient-boosted trees model) but only beginner Python and finance to follow.",
        "40": "The risk that a tree poses to line infrastructure (such as power lines) is determined by several factors, chief among them the height of the particular tree. The increasing availability of very high resolution satellite imagery makes it possible to use photogrammetric techniques to extract height information from a set of stereo satellite images. By using satellite imagery we can achieve a scale not possible by manual measurement. \r\nWe found that classical techniques perform poorly on vegetation, and were handily outperformed by deep learning based techniques implemented in PyTorch. This improvement was not trivial to achieve however, as creating labelled data in sufficient quantity was quite challenging. By increasing the quality of our height predictions we were able to more accurately calculate risk for our customers.",
        "22": "510, the Data & Digital initiative of the Netherlands Red Cross, is performing Social Media Listening on Telegram channels of Ukrainian refugees, to obtain insights in their needs. As a result, the Red Cross can direct its aid more purposefully. Obtaining such insights can be a time-intensive task, while in case of an emergency, one would like to initialize aid as quickly as possible. BERTopic has shown to be a powerful tool in quickly obtaining an overview of the discussion on social media. \r\n\r\nIn this presentation, a high-level explanation of BERTopic will be provided, which is a LLM-based method to obtain topics from a set of documents and categorize them accordingly. Other than basic machine learning knowledge, no further background knowledge is required. Rather than explaining how an LLM works, we will focus on what its task in BERTopic is. Next, we will discuss the evaluation of BERTopic, which is a challenging task, as it is an unsupervised method. Three different metrics are proposed, including an innovative approach that creates a test set with GPT. Finally, the application and results of BERTopic to the described use case will be discussed. This will show the practicality of BERTopic and hopefully inspire for other applications. \r\n\r\nTime breakdown:\r\n- Introduction to the Red Cross use case: 5 min\r\n- BERTopic: 10 min\r\n- Evaluation: 5 min\r\n- Application and results: 5 min\r\n- Q&A: 5 min",
        "69": "Retrieval Augmented Generation (RAG) is a popular technique to combine retrieval methods like vector search together with Large Language Models (LLM's). This gives us several advantages like retrieving extra information based on a user search query: allowing us to quote and cite LLM-generated answers. Because the underlying techniques are very broadly applicable, many types of data can be used to build up a RAG system, like textual data, tables, graphs or even images.\r\n\r\nIn this talk, we will deep dive into this popular emerging technique. Together, we will learn about: what the current state of RAG is, what you can expect to work well and what is still very challenging. \r\n\r\nJoin us if you \ud83e\udef5:\r\n- Are interested in GenAI \/ LLM's and RAG\r\n- Want to know more about the current state of RAG \r\n- Would like to know when you can most successfully apply RAG\r\n\r\n### Contents of the talk \ud83d\udccc\r\n1. [2 min] Intro\r\n2. [3 min] Why RAG?\r\n    1. The case for RAG\r\n    2. The RAG advantage\r\n    3. \u2026 so how-to RAG?\r\n3. [5 min] Level 0: Basic RAG\r\n    1. Which ingredients make up a successful RAG system?\r\n    2. Data ingestion\r\n    3. Chunking\r\n    4. Vector search\r\n    5. Answer generation\r\n4. [5 min] Level 1: Hybrid search\r\n    1. Combining multiple search methods with Reciprocal Rank Fusion\r\n    2. TF-IDF\r\n    3. BM-25\r\n5. [5 min] Level 2: Advanced data formats\r\n    1. The landscape of data formats \r\n    2. PDF parsing adventures\r\n    3. Tables\r\n    4. Graphs\r\n4. [5 min] Level 3: Going multimodal\r\n5. [4 min] Summing things up\r\n    1. The levels of RAG: from basic to advanced\r\n    2. GenAI community \ud83e\udec2\r\n    3. Concluding remarks\r\n6. [1 min] End\r\n\r\n[30 minutes total]\r\n\r\n\r\n### \u2764\ufe0f Open Source Software\r\nRAG and LLM\u2019s are presented in a cloud-agnostic way. Many of the software libraries mentioned are open source. There is no agenda for representing any major cloud.",
        "9": "There may be an opportunity to live code some of these examples, but if live coding is not possible it'd be preferable to know this ahead of time.",
        "32": "At CM.com we have released a new GenAI product (in 2023, built in Python) which is currently used by over 50 clients in various countries. GenAI is a chatbot that leverages the power of LLMs, while protecting against their common pitfalls such as incorrectness & inappropriateness, by using a Retrieval Augmented Generation framework (RAG).\r\n\r\nAs newer & better models rapidly arise, and our clients continue to provide feedback on the product, our own product development cannot lag behind. But how do we know whether changing from e.g. ChatGPT to Gemini or Llama improves the replies for all conversations? And how can you do prompt optimization if you don't know what you're optimizing against?  To help us maintain our current chatbot quality while investigating other models\/prompts, we have developed an evaluation framework in Python that can objectively evaluate several scenarios across a various of metrics. \r\n\r\nDuring these 30 minutes, I'll explain the principle behind RAG, highlight the huge development work being done in this field across the globe, give examples of several evaluation measures, and finally explain how we use these to move forward with our product. The talk is most interesting for Data Scientists and ML\/AI\/Prompt Engineers, but can be followed by anyone with some background knowledge on LLMs.",
        "21": "In this talk, we introduce switchback design, a method that addresses key challenges in marketplace experimentation faced by sectors like airlines and ride-sharing. It addresses traditional A\/B testing's limitations on small samples and subtle effects, highlighted by successes in companies like Uber, Lyft, and Doordash. This approach, crucial for accurate effect measurement, aims to boost decision-making and operational optimization, supported by a practical case study.\r\n\r\nTalk outline: \r\n- Introduction (5 mins): Quick intro to our expertise and the topic's relevance. \r\n- Challenges (5 mins): Overview of marketplace experimentation challenges. \r\n- Switchback Design (5 mins): Basics of switchback design vs. traditional A\/B testing. \r\n- Case Study (10 mins): Real-world application in the airline industry, showcasing benefits and drawbacks. \r\n- Key Takeaways (5 mins): Summary of our talk. \r\n- Q&A (10 mins): Open discussion for clarifications and further insights.\r\n\r\nThe intended audience: Targeted at data scientists, data analysts, product managers, and anyone interested in data-driven decision-making. Ideal for those curious about experimentation and causal inference in sectors like tech and e-commerce.\r\n\r\nNo background needed: Open to all levels, no prior knowledge needed. Concepts will be explained simply, focusing on practical insights without complex math.\r\n\r\nThe takeaway for the audience: The audience will understand the effectiveness of switchback design in overcoming marketplace experimentation hurdles, such as dealing with small samples and subtle effects. They'll learn from the success stories of top firms, understand practical steps for executing switchback experiments, and recognize its advantages over conventional A\/B testing for more informed decisions and improved results.",
        "55": "Causal Forecasting is a very hot topic in the industry with many applications ranging from marketing spending to pricing. Disentangling causal effects from spurious correlations plays a key role when forecasts are used for decision making, such as in the case of pricing. Solutions available in the industry typically rely on Machine Learning methods that use techniques like DoubleML, Transformers, LSTM, and boosted tree algorithms. A common shortcoming of such solutions is that they do not account for the existence of unobserved confounders, such as world events, or other hard-to-measure effects that can bias the measurement of causal effects. We showcase a solution that was developed over the last 3 years that addresses these challenges by combining advanced Econometrics methods with  ML techniques. The case-study will focus on the example of retail pricing, but the solution is broadly applicable and it has been tested in different settings, including airline pricing.",
        "59": "In this speech, we want to introduce an AI PC, a single machine capable of hosting diverse AI applications that can run GenAI in seconds, not hours. Such an approach for local AI allows us to overcome the usual issues associated with Cloud AI, such as the risk of data privacy breaches, high latency, and dependency on a connection to the cloud.\r\n\r\nBesides the AI PC, we will also showcase the OpenVINO Toolkit, which is an open-source toolkit for optimizing and deploying deep learning models. It helps to maximize the AI performance of the PC. Join our talk and see for yourself how the AI PC is well-suited for both generative and conventional AI models. All the presented demos, such as background blurring and image generation using a latent consistency model, are open-source and available on our GitHub.",
        "71": "A full description for this keynote will be announcIn a rapidly evolving landscape of semiconductor manufacturing, ASML\u2019s advanced lithography technologies are pivotal in driving Moore\u2019s Law forward. The focus of this talk is ASML\u2019s holistic approach to Software development and acceleration of Software delivery to customers. Key highlights include our innovative development environment, which fosters seamless integration and rapid iteration amongst teams. In addition, we discuss how ASML engages and cultivates Software talent through strategic initiatives and collaborative projects. By fostering a dynamic and innovative work environment, we empower our engineers to drive technological advancements and operational excellence.\r\n\r\nAt the end of this presentation the attendees will have an understanding of ASML\u2019s software ecosystem and its critical role in advancing the future of semiconductor fabrication.ed and added to the session when it becomes available.",
        "70": "Sonic Pi is a free code-based music creation and performance tool that targets both education and professional musicians. It is possible for beginners to code fresh beats, driving bass lines and shimmering synth riffs. All this whilst teaching core computer science concepts such as sequencing, functions, variables, loops, data structures and algorithms.\r\n\r\nThis talk will briefly introduce Sonic Pi before taking a deep technical nose-dive into some of the interesting requirements of live coding systems. We'll touch on concurrency, distributed programming, temporal logic, deterministic randomisation, event streams, hot swapping code and domain specific languages.\r\n\r\nGet ready for some serious live coded beats and a window into an exciting future of computing education."
    },
    "recording_license": {
        "17": "",
        "64": "",
        "25": "",
        "57": "",
        "54": "",
        "31": "",
        "40": "",
        "22": "",
        "69": "",
        "9": "",
        "32": "",
        "21": "",
        "55": "",
        "59": "",
        "71": "",
        "70": ""
    },
    "do_not_record": {
        "17": false,
        "64": false,
        "25": false,
        "57": false,
        "54": false,
        "31": false,
        "40": false,
        "22": false,
        "69": false,
        "9": false,
        "32": false,
        "21": false,
        "55": false,
        "59": false,
        "71": false,
        "70": false
    },
    "persons": {
        "17": [
            {
                "id": 25,
                "code": "LHNM7K",
                "public_name": "Sanne van den Bogaart",
                "biography": "For the past 3 years I have been working as a Data Science consultant at Pipple. Since Pipple is active in multiple different sectors, I have had the opportunity to do many different projects. What I have discovered is that explainability of the machine learning used was a critical topic in all of these projects. Fortunately, frameworks like LIME have emerged to provided this much needed explainability. I am excited to discuss more about LIME at the upcoming 2024 PyData Eindhoven conference.",
                "answers": []
            }
        ],
        "64": [
            {
                "id": 78,
                "code": "HRQY9D",
                "public_name": "Maria Medina",
                "biography": "Maria works as a Senior Data Scientist at Microsoft, currently based in The Netherlands. Her background is in computer science and mathematics and has 10+ years experience in data science consulting, using applied AI to solve business challenges in several industries and countries. She is also an advocate for diversity in technology and a former co-organizer of the PyLadies Madrid community.",
                "answers": []
            }
        ],
        "25": [
            {
                "id": 34,
                "code": "9WUZE9",
                "public_name": "Rob Claessens",
                "biography": "I'm working as a software engineer at Royal HaskoningDHV, a Dutch consulting and engineering firm. Both professionally and as a hobby, I have been delving into some AI-related subjects. I'm happy to give my first lecture at PyData Eindhoven, to share about my deep dive into Machine Learning, combined with my passion for cycling.",
                "answers": []
            }
        ],
        "57": [
            {
                "id": 40,
                "code": "VRCBRB",
                "public_name": "Max Brouwer",
                "biography": "Max works as Data Scientist for the Dutch Tennis Federation (KNLTB). Being part of both the technical staff and the Digital & IT team of the federation, he is involved in many projects for top and recreational tennis. Amongst other things, he works on implementing computer vision & machine learning techniques into match-analysis, on Elo-like rating systems, research, databasing and dashboarding.",
                "answers": []
            },
            {
                "id": 70,
                "code": "ATL7DQ",
                "public_name": "Matthias Kempe",
                "biography": "Dr. Matthias Kempe is an Assistant Professor of Data Science in Sports at the University of Groningen. He received his PhD in Sport Science at the German Sport University Cologne form the Faculty of Exercise Training and Sport Informatics. His research interests include performance optimization and decision making in team sports as well as sports analytics.  He cooperates with different sports federations in Germany and the Netherlands, especially in Handball, Ice-Skating, and Football. Besides that he worked together with Barca Innovation Hub and is a regular mentor for Hackathons (e.g. world data league).   This work has resulted in publications in journals such as Big Data, Journal of Sport Science, European Journal of Sport Science, and Experimental Aging Research",
                "answers": []
            }
        ],
        "54": [
            {
                "id": 68,
                "code": "BCNSWC",
                "public_name": "Yannis MOUDERE",
                "biography": "I am a French Data Scientist, holding an engineering diploma from Telecom Paris and a Master's degree from Institut Polytechnique de Paris in Applied Mathematics and Data Science.\r\nAt the end of my studies, I completed a Data Science internship at Parma Calcio 1913. I now serve as a full-time Data Scientist at the club, working on leveraging tracking data.",
                "answers": []
            }
        ],
        "31": [
            {
                "id": 42,
                "code": "D7YTNK",
                "public_name": "Pedro Tabacof",
                "biography": "Pedro Tabacof is based in Dublin and is currently a staff Machine Learning scientist at Intercom. Previously, he has worked at Wildlife Studios (mobile gaming), Nubank (fintech), iFood (food delivery app). He has used and deployed machine learning models for anti-fraud, credit risk, lifetime value and marketing attribution, using XGBoost or LightGBM in almost all cases. Academically, he has a master's degree in deep learning and 400+ citations.",
                "answers": []
            }
        ],
        "40": [
            {
                "id": 53,
                "code": "EJCLAA",
                "public_name": "Ferdinand Schenck",
                "biography": "I am a Machine Learning Engineer at LiveEO currently focused on applying Machine Learning techniques to remote sensing data.  \r\n\r\nBefore that, I did a PhD in particle physics at the Humboldt-Universit\u00e4t zu Berlin on the ATLAS experiment at CERN.",
                "answers": []
            }
        ],
        "22": [
            {
                "id": 30,
                "code": "FJBLSK",
                "public_name": "Nina van Diermen",
                "biography": "I recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.",
                "answers": []
            },
            {
                "id": 88,
                "code": "9FUMGJ",
                "public_name": "Nina van Diermen",
                "biography": "I recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.",
                "answers": []
            }
        ],
        "69": [
            {
                "id": 51,
                "code": "YM9JHZ",
                "public_name": "Jeroen Overschie",
                "biography": "Jeroen is a Machine Learning Engineer at Xebia Data (formerly GoDataDriven), in The Netherlands. Jeroen has a background in Software Engineering and Data Science and helps companies take their Machine Learning solutions into production.\r\nBesides his usual work, Jeroen has been active in the Open Source community. Jeroen published several PyPi modules, npm modules, and has contributed to several large open source projects (Hydra from Facebook and Emberfire from Google). Jeroen also authored two chrome extensions, which are published on the web store.",
                "answers": []
            }
        ],
        "9": [
            {
                "id": 15,
                "code": "G7KRFK",
                "public_name": "Vincent D. Warmerdam",
                "biography": "Vincent is a senior data professional, and recovering consultant, who worked as an engineer, researcher, team lead, and educator in the past. I\u2019m especially interested in understanding algorithmic systems so that one may prevent failure. As such, he prefers simpler solutions that scale and worry more about data quality than the number of tensors we throw at a problem. He's also well known for creating calmcode as well as a small dozen of open-source packages.\r\n\r\nHe's currently employed at probabl where he works together with scikit-learn core maintainers to improve the ecosystem of tooling.",
                "answers": []
            }
        ],
        "32": [
            {
                "id": 43,
                "code": "LKUKVW",
                "public_name": "Ennia Suijkerbuijk",
                "biography": "Ennia works as a Senior Data Scientist at CM.com. As part of the AI Tribe, she works on developing AI software solutions for companies across the globe. Her core focus nowadays lies with CM.com's state-of-the-art Generative AI Engine, which makes the power of LLMs & NLP available, easy to use and safe for companies in all sorts & sizes.",
                "answers": []
            }
        ],
        "21": [
            {
                "id": 32,
                "code": "GFKEBB",
                "public_name": "Nazli M. Alagoz",
                "biography": "Naz is a data scientist at ACMetric, a boutique Data Science & Artificial Intelligence Consulting firm. She specializes in leveraging causal inference and machine learning to improve experimentation and analysis. Alongside her work, she is in her final stages of Ph.D. in Quantitative Marketing. She is skilled in Python and R, turning complex data into clear insights and recommendations for stakeholders. Passionate about reproducible science, she is a data science blogger and speaker.",
                "answers": []
            },
            {
                "id": 86,
                "code": "EL3UZS",
                "public_name": "Jo\u00ebl Gastelaars",
                "biography": "Working on the edge of Business Strategy and Data Science. For me, it is all about converting business challenges into scalable data (science) solutions to create tangible value for the client. Currently leading the implementation of a company-wide experimentation & measurement platform in the airline industry and consulting on organizational change.\r\n\r\nBesides being a \"techy\", I like to make sure everyone understands what we do, why we do it and how it adds value for their business.",
                "answers": []
            }
        ],
        "55": [
            {
                "id": 69,
                "code": "N733EQ",
                "public_name": "Marc Nientker",
                "biography": "Marc Nientker transitioned from a successful seven-year academic career in econometrics, where he contributed as a PhD and Assistant Professor, to the business world to apply his knowledge on a broader scale. He co-founded Acmetric, a strategic data science consultancy that focuses on transforming businesses through data-driven insights.\r\n\r\nAcmetric specializes in practical applications of econometrics in areas such as pricing, inventory optimization, product allocation, measurement, and more. His expertise supports organizations in understanding and implementing data-centric strategies that naturally lead to more informed decision-making and operational efficiencies.",
                "answers": []
            }
        ],
        "59": [
            {
                "id": 74,
                "code": "JGCHB3",
                "public_name": "Dmitriy Pastushenkov",
                "biography": "Dmitriy Pastushenkov is a passionate AI PC Evangelist at Intel Germany\u00a0\u00a0with more than 20 years of comprehensive and international experience in industrial automation, industrial Internet of Things (IIoT), and real-time operating systems and AI. Dmitriy has held various roles in software development and enablement, software architecture, and technical management.\u00a0\u00a0\r\nDmitriy started his career at Intel in 2022 as a Software Architect. He works on the enablement and optimization of real-time, functional safety and AI workloads on the smart edge applying innovative Intel technologies and software products.\u00a0 Currently,\u00a0 as an AI PC Evangelist\u00a0Dmitriy focuses on OpenVINO  and other parts of the AI PC Software Stack.\r\nDmitriy has a Master\u2019s degree in Computer Science from Moscow Power Engineering Institute (Technical University).",
                "answers": []
            },
            {
                "id": 73,
                "code": "TAYW7K",
                "public_name": "Adrian Boguszewski",
                "biography": "AI Software Evangelist at Intel. Adrian graduated from the Gdansk University of Technology in the field of Computer Science 7 years ago. After that, he started his career in computer vision and deep learning. As a team leader of data scientists and Android developers for the previous two years, Adrian was responsible for an application to take a professional photo (for an ID card or passport) without leaving home. He is a co-author of the LandCover.ai dataset, creator of the OpenCV Image Viewer Plugin, and a Deep Learning lecturer occasionally. His current role is to educate people about OpenVINO Toolkit. In his free time, he\u2019s a traveler. You can also talk with him about finance, especially investments.",
                "answers": []
            }
        ],
        "71": [],
        "70": [
            {
                "id": 87,
                "code": "TBD3DK",
                "public_name": "Sam Aaron",
                "biography": null,
                "answers": []
            }
        ]
    },
    "links": {
        "17": [],
        "64": [],
        "25": [],
        "57": [],
        "54": [],
        "31": [],
        "40": [],
        "22": [],
        "69": [],
        "9": [],
        "32": [],
        "21": [],
        "55": [],
        "59": [],
        "71": [],
        "70": []
    },
    "attachments": {
        "17": [],
        "64": [],
        "25": [],
        "57": [],
        "54": [],
        "31": [],
        "40": [],
        "22": [],
        "69": [],
        "9": [],
        "32": [],
        "21": [],
        "55": [],
        "59": [],
        "71": [],
        "70": []
    },
    "answers": {
        "17": [],
        "64": [],
        "25": [],
        "57": [],
        "54": [],
        "31": [],
        "40": [],
        "22": [],
        "69": [],
        "9": [],
        "32": [],
        "21": [],
        "55": [],
        "59": [],
        "71": [],
        "70": []
    },
    "persons_text": {
        "17": " ### Sanne van den Bogaart\nFor the past 3 years I have been working as a Data Science consultant at Pipple. Since Pipple is active in multiple different sectors, I have had the opportunity to do many different projects. What I have discovered is that explainability of the machine learning used was a critical topic in all of these projects. Fortunately, frameworks like LIME have emerged to provided this much needed explainability. I am excited to discuss more about LIME at the upcoming 2024 PyData Eindhoven conference.\n",
        "64": " ### Maria Medina\nMaria works as a Senior Data Scientist at Microsoft, currently based in The Netherlands. Her background is in computer science and mathematics and has 10+ years experience in data science consulting, using applied AI to solve business challenges in several industries and countries. She is also an advocate for diversity in technology and a former co-organizer of the PyLadies Madrid community.\n",
        "25": " ### Rob Claessens\nI'm working as a software engineer at Royal HaskoningDHV, a Dutch consulting and engineering firm. Both professionally and as a hobby, I have been delving into some AI-related subjects. I'm happy to give my first lecture at PyData Eindhoven, to share about my deep dive into Machine Learning, combined with my passion for cycling.\n",
        "57": " ### Max Brouwer\nMax works as Data Scientist for the Dutch Tennis Federation (KNLTB). Being part of both the technical staff and the Digital & IT team of the federation, he is involved in many projects for top and recreational tennis. Amongst other things, he works on implementing computer vision & machine learning techniques into match-analysis, on Elo-like rating systems, research, databasing and dashboarding.\n\n ### Matthias Kempe\nDr. Matthias Kempe is an Assistant Professor of Data Science in Sports at the University of Groningen. He received his PhD in Sport Science at the German Sport University Cologne form the Faculty of Exercise Training and Sport Informatics. His research interests include performance optimization and decision making in team sports as well as sports analytics.  He cooperates with different sports federations in Germany and the Netherlands, especially in Handball, Ice-Skating, and Football. Besides that he worked together with Barca Innovation Hub and is a regular mentor for Hackathons (e.g. world data league).   This work has resulted in publications in journals such as Big Data, Journal of Sport Science, European Journal of Sport Science, and Experimental Aging Research\n",
        "54": " ### Yannis MOUDERE\nI am a French Data Scientist, holding an engineering diploma from Telecom Paris and a Master's degree from Institut Polytechnique de Paris in Applied Mathematics and Data Science.\r\nAt the end of my studies, I completed a Data Science internship at Parma Calcio 1913. I now serve as a full-time Data Scientist at the club, working on leveraging tracking data.\n",
        "31": " ### Pedro Tabacof\nPedro Tabacof is based in Dublin and is currently a staff Machine Learning scientist at Intercom. Previously, he has worked at Wildlife Studios (mobile gaming), Nubank (fintech), iFood (food delivery app). He has used and deployed machine learning models for anti-fraud, credit risk, lifetime value and marketing attribution, using XGBoost or LightGBM in almost all cases. Academically, he has a master's degree in deep learning and 400+ citations.\n",
        "40": " ### Ferdinand Schenck\nI am a Machine Learning Engineer at LiveEO currently focused on applying Machine Learning techniques to remote sensing data.  \r\n\r\nBefore that, I did a PhD in particle physics at the Humboldt-Universit\u00e4t zu Berlin on the ATLAS experiment at CERN.\n",
        "22": " ### Nina van Diermen\nI recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.\n\n ### Nina van Diermen\nI recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.\n",
        "69": " ### Jeroen Overschie\nJeroen is a Machine Learning Engineer at Xebia Data (formerly GoDataDriven), in The Netherlands. Jeroen has a background in Software Engineering and Data Science and helps companies take their Machine Learning solutions into production.\r\nBesides his usual work, Jeroen has been active in the Open Source community. Jeroen published several PyPi modules, npm modules, and has contributed to several large open source projects (Hydra from Facebook and Emberfire from Google). Jeroen also authored two chrome extensions, which are published on the web store.\n",
        "9": " ### Vincent D. Warmerdam\nVincent is a senior data professional, and recovering consultant, who worked as an engineer, researcher, team lead, and educator in the past. I\u2019m especially interested in understanding algorithmic systems so that one may prevent failure. As such, he prefers simpler solutions that scale and worry more about data quality than the number of tensors we throw at a problem. He's also well known for creating calmcode as well as a small dozen of open-source packages.\r\n\r\nHe's currently employed at probabl where he works together with scikit-learn core maintainers to improve the ecosystem of tooling.\n",
        "32": " ### Ennia Suijkerbuijk\nEnnia works as a Senior Data Scientist at CM.com. As part of the AI Tribe, she works on developing AI software solutions for companies across the globe. Her core focus nowadays lies with CM.com's state-of-the-art Generative AI Engine, which makes the power of LLMs & NLP available, easy to use and safe for companies in all sorts & sizes.\n",
        "21": " ### Nazli M. Alagoz\nNaz is a data scientist at ACMetric, a boutique Data Science & Artificial Intelligence Consulting firm. She specializes in leveraging causal inference and machine learning to improve experimentation and analysis. Alongside her work, she is in her final stages of Ph.D. in Quantitative Marketing. She is skilled in Python and R, turning complex data into clear insights and recommendations for stakeholders. Passionate about reproducible science, she is a data science blogger and speaker.\n\n ### Jo\u00ebl Gastelaars\nWorking on the edge of Business Strategy and Data Science. For me, it is all about converting business challenges into scalable data (science) solutions to create tangible value for the client. Currently leading the implementation of a company-wide experimentation & measurement platform in the airline industry and consulting on organizational change.\r\n\r\nBesides being a \"techy\", I like to make sure everyone understands what we do, why we do it and how it adds value for their business.\n",
        "55": " ### Marc Nientker\nMarc Nientker transitioned from a successful seven-year academic career in econometrics, where he contributed as a PhD and Assistant Professor, to the business world to apply his knowledge on a broader scale. He co-founded Acmetric, a strategic data science consultancy that focuses on transforming businesses through data-driven insights.\r\n\r\nAcmetric specializes in practical applications of econometrics in areas such as pricing, inventory optimization, product allocation, measurement, and more. His expertise supports organizations in understanding and implementing data-centric strategies that naturally lead to more informed decision-making and operational efficiencies.\n",
        "59": " ### Dmitriy Pastushenkov\nDmitriy Pastushenkov is a passionate AI PC Evangelist at Intel Germany\u00a0\u00a0with more than 20 years of comprehensive and international experience in industrial automation, industrial Internet of Things (IIoT), and real-time operating systems and AI. Dmitriy has held various roles in software development and enablement, software architecture, and technical management.\u00a0\u00a0\r\nDmitriy started his career at Intel in 2022 as a Software Architect. He works on the enablement and optimization of real-time, functional safety and AI workloads on the smart edge applying innovative Intel technologies and software products.\u00a0 Currently,\u00a0 as an AI PC Evangelist\u00a0Dmitriy focuses on OpenVINO  and other parts of the AI PC Software Stack.\r\nDmitriy has a Master\u2019s degree in Computer Science from Moscow Power Engineering Institute (Technical University).\n\n ### Adrian Boguszewski\nAI Software Evangelist at Intel. Adrian graduated from the Gdansk University of Technology in the field of Computer Science 7 years ago. After that, he started his career in computer vision and deep learning. As a team leader of data scientists and Android developers for the previous two years, Adrian was responsible for an application to take a professional photo (for an ID card or passport) without leaving home. He is a co-author of the LandCover.ai dataset, creator of the OpenCV Image Viewer Plugin, and a Deep Learning lecturer occasionally. His current role is to educate people about OpenVINO Toolkit. In his free time, he\u2019s a traveler. You can also talk with him about finance, especially investments.\n",
        "71": "",
        "70": " ### Sam Aaron\nNone\n"
    },
    "text": {
        "17": "# Explainable AI in the LIME-light\nLIME, a model-agnostic AI framework, illuminates the path to local explainability, primarily for classification models. Delving into the theory underpinning LIME, we explore diverse use cases and its adaptability across various scenarios. Through practical examples, we showcase the breadth of applications for LIME. By the presentation's conclusion, you'll have gained insights into leveraging LIME to clarify individual prediction logic, leading to more accessible explanations.\n\n## Description\nAlthough AI toolkits have simplified model implementation, understanding and interpreting these models remain challenging. With regulatory frameworks like the EU AI Act emphasizing explainability, the need for tools like LIME is paramount.\r\n\r\nThis presentation will provide an in-depth overview of LIME (Local Interpretable Model-agnostic Explanations), highlighting its utility in facilitating model comprehension. No prior expertise is assumed. Beginning with an explanation of LIME's theory and its practical implementation in Python, we'll then delve into diverse classification scenarios to showcase LIME's effectiveness. Additionally, we'll explore how the original LIME framework has been extended to handle time series data.\n\n## Timeslot\n2024-07-11T10:00:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Sanne van den Bogaart\nFor the past 3 years I have been working as a Data Science consultant at Pipple. Since Pipple is active in multiple different sectors, I have had the opportunity to do many different projects. What I have discovered is that explainability of the machine learning used was a critical topic in all of these projects. Fortunately, frameworks like LIME have emerged to provided this much needed explainability. I am excited to discuss more about LIME at the upcoming 2024 PyData Eindhoven conference.\n\n",
        "64": "# Risks and Mitigations for a Safe and Responsible AI\nThis talk will explain the multifaceted risks associated with building custom AI solutions, both from Responsible AI and Safety perspectives, and explore ways to mitigate them, to ensure that as AI professionals we create non-harmful AI systems.\n\n## Description\nThe rapid advancement of AI technologies, especially in the LLM space, is opening countless opportunities across all industries to apply in their daily business. However, it also introduces significant risks that could impact their users and broader society, from ethical and safety perspectives.\r\n\r\nIn this talk we will delve into various aspects to consider when building custom AI solutions to ensure they are not harmful in any way. We'll explain the types of risks to assess from both Responsible AI and Safety perspectives, and what mitigations can be implemented to address them. We'll discuss broad aspects that apply to all AI systems, such as fairness and inclusiveness, as well as risks specific to Large Language Models, like prompt injection attacks and hallucinations.\r\n \r\nBy the end of this talk, participants will have a clear understanding of AI risks, and a practical framework for evaluating and implementing responsible AI practices when building AI-based applications.\r\n \r\nThe talk is designed for anyone involved in the design and development of AI systems, from AI developers and data scientists to project managers. No technical knowledge is required, but a prior understanding of the fundamentals of AI and LLMs is assumed.\n\n## Timeslot\n2024-07-11T11:15:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Maria Medina\nMaria works as a Senior Data Scientist at Microsoft, currently based in The Netherlands. Her background is in computer science and mathematics and has 10+ years experience in data science consulting, using applied AI to solve business challenges in several industries and countries. She is also an advocate for diversity in technology and a former co-organizer of the PyLadies Madrid community.\n\n",
        "25": "# Predicting the Spring Classics of cycling with my first neural network\nLast year I attended PyData Eindhoven for the first time. I got inspired and now I\u2019m back to present my first neural network, a network that was trained to predict the Spring Classics of cycling! With this neural network, I\u2019m attempting to beat my friends, and myself, in a well-known fantasy cycling game.\n\n## Description\nLast year I attended PyData Eindhoven for the first time. I got inspired and now I\u2019m back to present my first neural network, a network that was trained to predict the Spring Classics of cycling! With this neural network, I\u2019m attempting to beat my friends, and myself, in a well-known fantasy cycling game.\r\n\r\nIn this talk, I will elaborate on the process of building a model from scratch. This will include data collection, model training and finetuning, and of course a discussion of the predicted results. The predictions will also be compared to an existing cycling prediction platform that I use as benchmark. Lastly, I\u2019ll try to provide some insights into the model using SHAP values.\n\n## Timeslot\n2024-07-11T12:00:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Rob Claessens\nI'm working as a software engineer at Royal HaskoningDHV, a Dutch consulting and engineering firm. Both professionally and as a hobby, I have been delving into some AI-related subjects. I'm happy to give my first lecture at PyData Eindhoven, to share about my deep dive into Machine Learning, combined with my passion for cycling.\n\n",
        "57": "# Computer vision at the Dutch Tennis Federation: Utilizing YOLO to create insights for coaches\nThrough single-camera tennis match footage, via a YOLO-driven computer vision system, and culminating in actionable insights for strength and conditioning coaches, the Dutch Tennis Federation offers a pathway for creating tennis data and insights. In our presentation, we will delve into technical specifications and algorithms of our system, navigate through the challenges of working with tennis video footage, and elaborate on our approach to actively engage coaches in our co-creation approach. After the presentation, you will have a deeper understanding of the intricate workings behind implementing such system in a competitive tennis environment. All output of the project will be presented on Github.\n\n## Description\nTennis is seen within the community more as a skill sport than a physical sport. In this way, tennis is an exception compared to other ball sports, in which there is a primary focus on physical data (e.g., distance covered or time in specific speed zones). The primary use of data by now is tactical analysis, scouting your opponent, and finding specific tendencies. Currently, this is done by manually annotating events in game videos for further analysis, which can take up to 5 hours per match. One of the bottlenecks of this process is finding the start of a rally; the effective playing time is actually just 20-30% on clay courts and 10-15% on fast courts. This means that a 5-hour match would have just 30 minutes of playing time that needs to be annotated. Hence, automatically finding the start point of a rally and cutting videos into shorter sequences would tremendously speed up the annotation process and would allow scouting of more players and matches. \r\n\r\nIn turn, we had two goals in the project. First, to create a solution to optimize the annotation process by providing videos when the ball is in play. The second goal was to provide tennis coaches and players with physical data and to stimulate the use of this type of data (user buy-in). For both of these goals, we faced specific challenges we needed to overcome. Event recognition has been achieved in other sports as well as in tennis using computer vision approaches, especially video tracking (trajectories and coordinates of the players). In tennis, the Hawk-Eye system is used in big tournaments to provide this information. By using 10 synchronized cameras, the system provides player and ball trajectories that enable event recognition and the extraction of physical variables. However, due to the costs of using this system and the complexity of installing it, using it in less prestigious tournaments or for training monitoring is not an option. To overcome this challenge, we created a one-camera computer vision system that allows for player tracking and simple event recognition. \r\n\r\nAs mentioned earlier, the second challenge of this project is the buy-in by coaches, athletes, and the medical team to physical parameters for athlete monitoring and training optimization. To overcome this problem, we opted for an educational and co-creation approach. This entails, in an initial step, a presentation on the usage of physical data in other sports and their benefits. In a second step, we performed semi-structured interviews with potential end-users (coaches, athletes, medical staff, and performance analysts). Based on these interactive interviews, important variables for the end-users were defined. In addition, potential forms of data presentation and visualizations were discussed in order to create a dashboard for the end-users. In doing so, we improved the understanding of the end-users as well as the commitment to the project. \r\n\r\nIn this talk, we will provide a summary of the general approach of the conducted interviews and how this resulted in an interactive dashboard for coaches, athletes, and analysts. In addition, we provide an overview of the pipeline of the computer vision approach. While using an \u201coff-the-shelf\u201d YOLO approach, several processing steps are necessary. This includes several technical challenges like player and court recognition as well as data filtering. We will also provide an example of how we enriched our pipeline with audio data to facilitate event recognition. All in all, we hope to provide an exemplary approach on how to conduct a data science project in a sports environment in which the conceptual barriers between product designer and end-user are often hard to overcome.\n\n## Timeslot\n2024-07-11T14:00:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Max Brouwer\nMax works as Data Scientist for the Dutch Tennis Federation (KNLTB). Being part of both the technical staff and the Digital & IT team of the federation, he is involved in many projects for top and recreational tennis. Amongst other things, he works on implementing computer vision & machine learning techniques into match-analysis, on Elo-like rating systems, research, databasing and dashboarding.\n\n ### Matthias Kempe\nDr. Matthias Kempe is an Assistant Professor of Data Science in Sports at the University of Groningen. He received his PhD in Sport Science at the German Sport University Cologne form the Faculty of Exercise Training and Sport Informatics. His research interests include performance optimization and decision making in team sports as well as sports analytics.  He cooperates with different sports federations in Germany and the Netherlands, especially in Handball, Ice-Skating, and Football. Besides that he worked together with Barca Innovation Hub and is a regular mentor for Hackathons (e.g. world data league).   This work has resulted in publications in journals such as Big Data, Journal of Sport Science, European Journal of Sport Science, and Experimental Aging Research\n\n",
        "54": "# Enhancing Event Analysis at Scale: Leveraging Tracking Data in Sports.\nLearn how to automate the generation of contextual metrics from tracking data to enrich event analysis, handling the influx of games arriving daily in an efficient way by scaling-out the entire architecture.\n\n## Description\nIn the dynamic landscape of sports analytics, the integration of tracking data has opened new frontiers for in-depth event analysis. Yet, the use of this data remains a bottleneck, particularly when dealing with a large volume of games. Indeed, such computation is either too expensive or too long. The focus of the presentation will be on automating the generation of these contextual metrics at scale, and their usage by professionals and decision-makers.\r\nThe presentation will showcase an architecture and an automated pipeline designed to handle the influx of games. Leveraging Python and cloud computing services such as message queues, we efficiently manage incoming game data by scaling the infrastructure based on the workload, ensuring optimal performance during peak period while minimizing costs during quieter times. The presentation will strike a balance between technical depth and practical application. Attendees will gain insights into the architecture required to efficiently process hundreds of games weekly, while accommodating the thousands already present in the database. The advantage granted by this method will be quantified in terms of time and resources to inform data scientists and data engineers the efficiency they could reach.\n\n## Timeslot\n2024-07-11T14:45:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Yannis MOUDERE\nI am a French Data Scientist, holding an engineering diploma from Telecom Paris and a Master's degree from Institut Polytechnique de Paris in Applied Mathematics and Data Science.\r\nAt the end of my studies, I completed a Data Science internship at Parma Calcio 1913. I now serve as a full-time Data Scientist at the club, working on leveraging tracking data.\n\n",
        "31": "# How I lost 1000\u20ac betting on CS:GO with machine learning and Python\nPeople have been using machine learning for sports betting for decades. Logistic regression applied to horse racing made someone a multi-millionaire in the 80s. While fun, betting is a losing proposition for most. The house always wins, right?\r\n\r\nWith a friend, I thought we could beat the house in e-sports by leveraging modern ML tools like LightGBM. E-sports betting is less sophisticated than football or horse racing i.e. the market is less efficient. There is a lot of online data and unknown teams. It was a space ripe for money-making, or so we thought.\r\n\r\nFirst, I will explain the theory behind e-sports betting with ML: what is an edge, financial decision-making, the expected value and decision rule for one bet, multiple bets with the Kelly criterion, probability calibration and the winner's curse.\r\n\r\nThen, I will explain how we built a web scraper to extract features, developed a probabilistic classifier using LightGBM, defined betting rules using the Kelly criterion, backtested it with a positive ROI, and then lost actual money, with many priceless lessons coming out of it.\n\n## Description\nThis presentation goes in-depth on how to use ML for e-sports betting and the pitfalls one might fall in. More broadly, I try to connect ML with financial decision-making, which can be applied in other domains too (credit, fraud, marketing), targeting data scientists and ML practitioners who are interested in financial applications.\r\n\r\nFinancial decision-making is not just about being right (predictive modelling) but also about acting rightly (betting\/trading strategy). To act correctly, one must understand concepts such as an edge, expected value\/profits, probability calibration, winner's curse (selection bias), and so on. More importantly, any trading or betting strategy needs to be thoroughly validated with backtests and paper-trades and the risk and profitability quantified. My aim is to cover some of those important foundational topics, while providing pointers for further studies.\r\n\r\nThe presentation is divided into two parts: \r\n\r\n1. Foundations of ML applied to betting (15 min)\r\n   * What is your edge?\r\n   * Financial decision-making with ML\r\n   * One bet: Expected profits and decision rule\r\n   * Multiple bets: The Kelly criterion\r\n   * Probability calibration\r\n   * Winner\u2019s curse\r\n2. CS:GO betting (10 min)\r\n   * Data scraping\r\n   * Feature engineering\r\n   * TrueSkill (with a side note on inferential vs predictive models)\r\n   * Modelling\r\n   * Evaluation\r\n   * Backtesting\r\n   * Why I lost 1000 euros\r\n\r\nThat is, I will present both the theory and practice, using my own failure as an illustrative example for the lessons shown. The presentation will have two companion blog posts with reproducible Python code.\r\n\r\nThis presentation requires mid-level data science knowledge (e.g. how to train a gradient-boosted trees model) but only beginner Python and finance to follow.\n\n## Timeslot\n2024-07-11T16:05:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Pedro Tabacof\nPedro Tabacof is based in Dublin and is currently a staff Machine Learning scientist at Intercom. Previously, he has worked at Wildlife Studios (mobile gaming), Nubank (fintech), iFood (food delivery app). He has used and deployed machine learning models for anti-fraud, credit risk, lifetime value and marketing attribution, using XGBoost or LightGBM in almost all cases. Academically, he has a master's degree in deep learning and 400+ citations.\n\n",
        "40": "# \ud83c\udf33 The taller the tree, the harder the fall. Determining tree height from space using Deep Learning and very high resolution satellite imagery \ud83d\udef0\ufe0f\nA case study of how we use Deep Learning based photogrammetry to calculate the height of trees from very high resolution satellite imagery. We show the substantial improvement achieved by switching from classical photogrammetric techniques to a deep learning based model (implemented in PyTorch), and the challenges we had to overcome to make this solution work.\n\n## Description\nThe risk that a tree poses to line infrastructure (such as power lines) is determined by several factors, chief among them the height of the particular tree. The increasing availability of very high resolution satellite imagery makes it possible to use photogrammetric techniques to extract height information from a set of stereo satellite images. By using satellite imagery we can achieve a scale not possible by manual measurement. \r\nWe found that classical techniques perform poorly on vegetation, and were handily outperformed by deep learning based techniques implemented in PyTorch. This improvement was not trivial to achieve however, as creating labelled data in sufficient quantity was quite challenging. By increasing the quality of our height predictions we were able to more accurately calculate risk for our customers.\n\n## Timeslot\n2024-07-11T16:50:00+02:00 with a duration of 00:30\n\n## Room\nIf (1.1)\n\n## Speaker\n ### Ferdinand Schenck\nI am a Machine Learning Engineer at LiveEO currently focused on applying Machine Learning techniques to remote sensing data.  \r\n\r\nBefore that, I did a PhD in particle physics at the Humboldt-Universit\u00e4t zu Berlin on the ATLAS experiment at CERN.\n\n",
        "22": "# BERTopic to accelerate Ukrainian aid by the Red Cross\nBy means of Topic Modeling, discussed topics can be subtracted from a set of documents. BERTopic is a way of Topic Modeling that uses Large Language Models. A high-level overview of how BERTopic works will be presented, together with its evaluation and the application of it on a use case of the Netherlands Red Cross. In this use case, BERTopic supports in getting insights into the needs of Ukrainian refugees as expressed through social media.  This presentation will help in understanding BERTopic and might inspire for other valuable use cases within your own field.\n\n## Description\n510, the Data & Digital initiative of the Netherlands Red Cross, is performing Social Media Listening on Telegram channels of Ukrainian refugees, to obtain insights in their needs. As a result, the Red Cross can direct its aid more purposefully. Obtaining such insights can be a time-intensive task, while in case of an emergency, one would like to initialize aid as quickly as possible. BERTopic has shown to be a powerful tool in quickly obtaining an overview of the discussion on social media. \r\n\r\nIn this presentation, a high-level explanation of BERTopic will be provided, which is a LLM-based method to obtain topics from a set of documents and categorize them accordingly. Other than basic machine learning knowledge, no further background knowledge is required. Rather than explaining how an LLM works, we will focus on what its task in BERTopic is. Next, we will discuss the evaluation of BERTopic, which is a challenging task, as it is an unsupervised method. Three different metrics are proposed, including an innovative approach that creates a test set with GPT. Finally, the application and results of BERTopic to the described use case will be discussed. This will show the practicality of BERTopic and hopefully inspire for other applications. \r\n\r\nTime breakdown:\r\n- Introduction to the Red Cross use case: 5 min\r\n- BERTopic: 10 min\r\n- Evaluation: 5 min\r\n- Application and results: 5 min\r\n- Q&A: 5 min\n\n## Timeslot\n2024-07-11T10:00:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Nina van Diermen\nI recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.\n\n ### Nina van Diermen\nI recently graduated from my master Business Analytics and Operations Research. To complete my master, I wrote my thesis about accelerating Ukrainian Aid by the Red Cross with BERTopic. During PyData, I am happy to tell you more about this cool research project. As of mid June, I started as a Data Scientist at Pipple. In my spare time, I like to play volleyball or go for a run.\n\n",
        "69": "# The Levels of RAG \ud83e\udd9c\nLLM's can be supercharged using a technique called RAG, allowing us to overcome dealbreaker problems like hallucinations or no access to internal data. RAG is gaining more industry momentum and is becoming rapidly more mature both in the open-source world and at major Cloud vendors. But what can we expect from RAG? What is the current state of the tech in the industry? What use-cases work well and which are more challenging? Let's find out together!\n\n## Description\nRetrieval Augmented Generation (RAG) is a popular technique to combine retrieval methods like vector search together with Large Language Models (LLM's). This gives us several advantages like retrieving extra information based on a user search query: allowing us to quote and cite LLM-generated answers. Because the underlying techniques are very broadly applicable, many types of data can be used to build up a RAG system, like textual data, tables, graphs or even images.\r\n\r\nIn this talk, we will deep dive into this popular emerging technique. Together, we will learn about: what the current state of RAG is, what you can expect to work well and what is still very challenging. \r\n\r\nJoin us if you \ud83e\udef5:\r\n- Are interested in GenAI \/ LLM's and RAG\r\n- Want to know more about the current state of RAG \r\n- Would like to know when you can most successfully apply RAG\r\n\r\n### Contents of the talk \ud83d\udccc\r\n1. [2 min] Intro\r\n2. [3 min] Why RAG?\r\n    1. The case for RAG\r\n    2. The RAG advantage\r\n    3. \u2026 so how-to RAG?\r\n3. [5 min] Level 0: Basic RAG\r\n    1. Which ingredients make up a successful RAG system?\r\n    2. Data ingestion\r\n    3. Chunking\r\n    4. Vector search\r\n    5. Answer generation\r\n4. [5 min] Level 1: Hybrid search\r\n    1. Combining multiple search methods with Reciprocal Rank Fusion\r\n    2. TF-IDF\r\n    3. BM-25\r\n5. [5 min] Level 2: Advanced data formats\r\n    1. The landscape of data formats \r\n    2. PDF parsing adventures\r\n    3. Tables\r\n    4. Graphs\r\n4. [5 min] Level 3: Going multimodal\r\n5. [4 min] Summing things up\r\n    1. The levels of RAG: from basic to advanced\r\n    2. GenAI community \ud83e\udec2\r\n    3. Concluding remarks\r\n6. [1 min] End\r\n\r\n[30 minutes total]\r\n\r\n\r\n### \u2764\ufe0f Open Source Software\r\nRAG and LLM\u2019s are presented in a cloud-agnostic way. Many of the software libraries mentioned are open source. There is no agenda for representing any major cloud.\n\n## Timeslot\n2024-07-11T11:15:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Jeroen Overschie\nJeroen is a Machine Learning Engineer at Xebia Data (formerly GoDataDriven), in The Netherlands. Jeroen has a background in Software Engineering and Data Science and helps companies take their Machine Learning solutions into production.\r\nBesides his usual work, Jeroen has been active in the Open Source community. Jeroen published several PyPi modules, npm modules, and has contributed to several large open source projects (Hydra from Facebook and Emberfire from Google). Jeroen also authored two chrome extensions, which are published on the web store.\n\n",
        "9": "# Scikit-Learn can do THAT?!\nMany of us know scikit-learn for it's ability to construct pipelines that can do .fit().predict(). It's an amazing feature for sure. But once you dive into the codebase ... you realise that there is just so much more. \r\n\r\nThis talk will be an attempt at demonstrating some extra features in scikit-learn, and it's ecosystem, that are less common but deserve to be in the spotlight. \r\n\r\nIn particular I hope to discuss these things that scikit-learn can do:\r\n\r\n- sparse datasets and models\r\n- larger than memory datasets\r\n- sample weight techniques\r\n- image classification via embeddings\r\n- tabular embeddings\/vectorisation \r\n- data deduplication\r\n- pipeline caching\r\n\r\nIf time allows I may also touch on extra topics.\n\n## Description\nThere may be an opportunity to live code some of these examples, but if live coding is not possible it'd be preferable to know this ahead of time.\n\n## Timeslot\n2024-07-11T12:00:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Vincent D. Warmerdam\nVincent is a senior data professional, and recovering consultant, who worked as an engineer, researcher, team lead, and educator in the past. I\u2019m especially interested in understanding algorithmic systems so that one may prevent failure. As such, he prefers simpler solutions that scale and worry more about data quality than the number of tensors we throw at a problem. He's also well known for creating calmcode as well as a small dozen of open-source packages.\r\n\r\nHe's currently employed at probabl where he works together with scikit-learn core maintainers to improve the ecosystem of tooling.\n\n",
        "32": "# Evaluating LLM Frameworks\nLarge Language Models are everywhere these days. But how can you objectively evaluate whether a model or a prompt is performing properly? Let's dive into the world of LLM evaluation frameworks!\n\n## Description\nAt CM.com we have released a new GenAI product (in 2023, built in Python) which is currently used by over 50 clients in various countries. GenAI is a chatbot that leverages the power of LLMs, while protecting against their common pitfalls such as incorrectness & inappropriateness, by using a Retrieval Augmented Generation framework (RAG).\r\n\r\nAs newer & better models rapidly arise, and our clients continue to provide feedback on the product, our own product development cannot lag behind. But how do we know whether changing from e.g. ChatGPT to Gemini or Llama improves the replies for all conversations? And how can you do prompt optimization if you don't know what you're optimizing against?  To help us maintain our current chatbot quality while investigating other models\/prompts, we have developed an evaluation framework in Python that can objectively evaluate several scenarios across a various of metrics. \r\n\r\nDuring these 30 minutes, I'll explain the principle behind RAG, highlight the huge development work being done in this field across the globe, give examples of several evaluation measures, and finally explain how we use these to move forward with our product. The talk is most interesting for Data Scientists and ML\/AI\/Prompt Engineers, but can be followed by anyone with some background knowledge on LLMs.\n\n## Timeslot\n2024-07-11T14:00:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Ennia Suijkerbuijk\nEnnia works as a Senior Data Scientist at CM.com. As part of the AI Tribe, she works on developing AI software solutions for companies across the globe. Her core focus nowadays lies with CM.com's state-of-the-art Generative AI Engine, which makes the power of LLMs & NLP available, easy to use and safe for companies in all sorts & sizes.\n\n",
        "21": "# Maximizing marketplace experimentation: switchback design for small samples and subtle effects\nConventional A\/B testing often falls short in industries such as airlines, ride-sharing, and delivery services, where challenges like small samples and subtle effects complicate testing new features. Inspired by its significant impact in leading companies like Uber, Lyft, and Doordash, we introduce the switchback design as a practical alternative to conventional A\/B testing. By addressing small sample size limitations and the need to detect subtle effects quickly, this approach boosts statistical power while reducing variability and interference. We guide the audience through the challenges of marketplace experimentation and implementing this approach, period length optimization and switch frequency using a case study from the airline industry.\n\n## Description\nIn this talk, we introduce switchback design, a method that addresses key challenges in marketplace experimentation faced by sectors like airlines and ride-sharing. It addresses traditional A\/B testing's limitations on small samples and subtle effects, highlighted by successes in companies like Uber, Lyft, and Doordash. This approach, crucial for accurate effect measurement, aims to boost decision-making and operational optimization, supported by a practical case study.\r\n\r\nTalk outline: \r\n- Introduction (5 mins): Quick intro to our expertise and the topic's relevance. \r\n- Challenges (5 mins): Overview of marketplace experimentation challenges. \r\n- Switchback Design (5 mins): Basics of switchback design vs. traditional A\/B testing. \r\n- Case Study (10 mins): Real-world application in the airline industry, showcasing benefits and drawbacks. \r\n- Key Takeaways (5 mins): Summary of our talk. \r\n- Q&A (10 mins): Open discussion for clarifications and further insights.\r\n\r\nThe intended audience: Targeted at data scientists, data analysts, product managers, and anyone interested in data-driven decision-making. Ideal for those curious about experimentation and causal inference in sectors like tech and e-commerce.\r\n\r\nNo background needed: Open to all levels, no prior knowledge needed. Concepts will be explained simply, focusing on practical insights without complex math.\r\n\r\nThe takeaway for the audience: The audience will understand the effectiveness of switchback design in overcoming marketplace experimentation hurdles, such as dealing with small samples and subtle effects. They'll learn from the success stories of top firms, understand practical steps for executing switchback experiments, and recognize its advantages over conventional A\/B testing for more informed decisions and improved results.\n\n## Timeslot\n2024-07-11T14:45:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Nazli M. Alagoz\nNaz is a data scientist at ACMetric, a boutique Data Science & Artificial Intelligence Consulting firm. She specializes in leveraging causal inference and machine learning to improve experimentation and analysis. Alongside her work, she is in her final stages of Ph.D. in Quantitative Marketing. She is skilled in Python and R, turning complex data into clear insights and recommendations for stakeholders. Passionate about reproducible science, she is a data science blogger and speaker.\n\n ### Jo\u00ebl Gastelaars\nWorking on the edge of Business Strategy and Data Science. For me, it is all about converting business challenges into scalable data (science) solutions to create tangible value for the client. Currently leading the implementation of a company-wide experimentation & measurement platform in the airline industry and consulting on organizational change.\r\n\r\nBesides being a \"techy\", I like to make sure everyone understands what we do, why we do it and how it adds value for their business.\n\n",
        "55": "# Causal Forecasting: How to disentangle causal effects, while controlling for unobserved confounders and keeping accuracy\nA lot of industry-available Machine Learning solutions for causal forecasting have a very particular blind spot: unobserved confounders. We will present an approach that allows you to combine state-of-the-art Machine Learning approaches with advanced Econometrics techniques to get the better of both worlds: accurate causal inference and good forecasting accuracy.\n\n## Description\nCausal Forecasting is a very hot topic in the industry with many applications ranging from marketing spending to pricing. Disentangling causal effects from spurious correlations plays a key role when forecasts are used for decision making, such as in the case of pricing. Solutions available in the industry typically rely on Machine Learning methods that use techniques like DoubleML, Transformers, LSTM, and boosted tree algorithms. A common shortcoming of such solutions is that they do not account for the existence of unobserved confounders, such as world events, or other hard-to-measure effects that can bias the measurement of causal effects. We showcase a solution that was developed over the last 3 years that addresses these challenges by combining advanced Econometrics methods with  ML techniques. The case-study will focus on the example of retail pricing, but the solution is broadly applicable and it has been tested in different settings, including airline pricing.\n\n## Timeslot\n2024-07-11T16:05:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Marc Nientker\nMarc Nientker transitioned from a successful seven-year academic career in econometrics, where he contributed as a PhD and Assistant Professor, to the business world to apply his knowledge on a broader scale. He co-founded Acmetric, a strategic data science consultancy that focuses on transforming businesses through data-driven insights.\r\n\r\nAcmetric specializes in practical applications of econometrics in areas such as pricing, inventory optimization, product allocation, measurement, and more. His expertise supports organizations in understanding and implementing data-centric strategies that naturally lead to more informed decision-making and operational efficiencies.\n\n",
        "59": "# Cloud? No Thanks! I\u2019m Gonna Run GenAI on My AI PC\nIn this speech, we want to introduce an AI PC, a single machine that consists of a CPU, GPU, and NPU (Neural Processing Unit) and can run GenAI in seconds, not hours. Besides the hardware, we will also show the OpenVINO Toolkit, a software solution that helps squeeze as much as possible out of that PC. Join our talk and see for yourself the AI PC is good for both generative and conventional AI models. All presented demos are open source and available on our GitHub.\n\n## Description\nIn this speech, we want to introduce an AI PC, a single machine capable of hosting diverse AI applications that can run GenAI in seconds, not hours. Such an approach for local AI allows us to overcome the usual issues associated with Cloud AI, such as the risk of data privacy breaches, high latency, and dependency on a connection to the cloud.\r\n\r\nBesides the AI PC, we will also showcase the OpenVINO Toolkit, which is an open-source toolkit for optimizing and deploying deep learning models. It helps to maximize the AI performance of the PC. Join our talk and see for yourself how the AI PC is well-suited for both generative and conventional AI models. All the presented demos, such as background blurring and image generation using a latent consistency model, are open-source and available on our GitHub.\n\n## Timeslot\n2024-07-11T16:50:00+02:00 with a duration of 00:30\n\n## Room\nElse (1.3)\n\n## Speaker\n ### Dmitriy Pastushenkov\nDmitriy Pastushenkov is a passionate AI PC Evangelist at Intel Germany\u00a0\u00a0with more than 20 years of comprehensive and international experience in industrial automation, industrial Internet of Things (IIoT), and real-time operating systems and AI. Dmitriy has held various roles in software development and enablement, software architecture, and technical management.\u00a0\u00a0\r\nDmitriy started his career at Intel in 2022 as a Software Architect. He works on the enablement and optimization of real-time, functional safety and AI workloads on the smart edge applying innovative Intel technologies and software products.\u00a0 Currently,\u00a0 as an AI PC Evangelist\u00a0Dmitriy focuses on OpenVINO  and other parts of the AI PC Software Stack.\r\nDmitriy has a Master\u2019s degree in Computer Science from Moscow Power Engineering Institute (Technical University).\n\n ### Adrian Boguszewski\nAI Software Evangelist at Intel. Adrian graduated from the Gdansk University of Technology in the field of Computer Science 7 years ago. After that, he started his career in computer vision and deep learning. As a team leader of data scientists and Android developers for the previous two years, Adrian was responsible for an application to take a professional photo (for an ID card or passport) without leaving home. He is a co-author of the LandCover.ai dataset, creator of the OpenCV Image Viewer Plugin, and a Deep Learning lecturer occasionally. His current role is to educate people about OpenVINO Toolkit. In his free time, he\u2019s a traveler. You can also talk with him about finance, especially investments.\n\n",
        "71": "# Software at ASML: the Force behind making microchips\nIn a rapidly evolving landscape of semiconductor manufacturing, ASML\u2019s advanced lithography technologies are pivotal in driving Moore\u2019s Law forward. The focus of this talk is ASML\u2019s holistic approach to Software development and acceleration of Software delivery to customers. In addition, we discuss how ASML engages and cultivates Software talents. At the end of this presentation the attendees will have an understanding of ASML\u2019s software ecosystem and its critical role in advancing the future.\n\n## Description\nA full description for this keynote will be announcIn a rapidly evolving landscape of semiconductor manufacturing, ASML\u2019s advanced lithography technologies are pivotal in driving Moore\u2019s Law forward. The focus of this talk is ASML\u2019s holistic approach to Software development and acceleration of Software delivery to customers. Key highlights include our innovative development environment, which fosters seamless integration and rapid iteration amongst teams. In addition, we discuss how ASML engages and cultivates Software talent through strategic initiatives and collaborative projects. By fostering a dynamic and innovative work environment, we empower our engineers to drive technological advancements and operational excellence.\r\n\r\nAt the end of this presentation the attendees will have an understanding of ASML\u2019s software ecosystem and its critical role in advancing the future of semiconductor fabrication.ed and added to the session when it becomes available.\n\n## Timeslot\n2024-07-11T09:00:00+02:00 with a duration of 00:50\n\n## Room\nREPL (2, mainstage)\n\n## Speaker\n\n",
        "70": "# Sonic Pi - Live Coding as a tool for next-gen education.\nSonic Pi is a free code-based music creation and performance tool that targets both education and professional musicians. It is possible for beginners to code fresh beats, driving bass lines and shimmering synth riffs. All this whilst teaching core computer science concepts such as sequencing, functions, variables, loops, data structures and algorithms.\r\n\r\nThis talk will briefly introduce Sonic Pi before taking a deep technical nose-dive into some of the interesting requirements of live coding.\n\n## Description\nSonic Pi is a free code-based music creation and performance tool that targets both education and professional musicians. It is possible for beginners to code fresh beats, driving bass lines and shimmering synth riffs. All this whilst teaching core computer science concepts such as sequencing, functions, variables, loops, data structures and algorithms.\r\n\r\nThis talk will briefly introduce Sonic Pi before taking a deep technical nose-dive into some of the interesting requirements of live coding systems. We'll touch on concurrency, distributed programming, temporal logic, deterministic randomisation, event streams, hot swapping code and domain specific languages.\r\n\r\nGet ready for some serious live coded beats and a window into an exciting future of computing education.\n\n## Timeslot\n2024-07-11T17:30:00+02:00 with a duration of 01:00\n\n## Room\nREPL (2, mainstage)\n\n## Speaker\n ### Sam Aaron\nNone\n\n"
    }
}